# 传输层

## 传输服务

1. 在应用程序看来，源进程向本地套接字写入报文或数据，目的进程在本地套接字即可收到报文或数据，**传输层提供了进程间的逻辑通信**

2. 传输层看来，发送端传输层将报文交给本地的网络层接口，接收端传输层从本地网络层接口即可收到报文，**网络层提供了终端间的逻辑通信**

3. 网络层提供**尽力而为**的服务，**不提供任何承诺**，不保证交付，不保证按序交付，不保证数据完整，不保证延迟，不保证带宽

4. 传输层不能提供延迟保证和带宽保证，但可以保证可靠/按序交付 (TCP)，也可能不保证 (UDP)

## 多路复用和解复用

1. 传输层基本服务是将主机间交付扩展到进程间交付

2. (发送端) 多路复用：传输层从多个套接字收集数据，交给网络层发送

3. (接收端) 解复用：传输层将收到的数据交付到正确的套接字

4. 主机中每个套接字应分配一个唯一的标识，报文段中包含接收套接字的标识

5. 端口号是套接字标识的一部分，每个套接字在本地关联一个端口号，一个16比特的数，报文段中源端口号和目的端口号都携带端口号

6. 分配端口号
   - 自动分配，从1024-65535
   - 指定端口号

7. UDP 标识 <目的IP地址，目的端口号> 或 <源IP地址，源端口号>，TCP 连接套接字标识 <源 IP 地址，目的 IP 地址，源端口号，目的端口号>

## 无连接传输 - UDP

1. UDP 提供的服务，进程到进程间的报文交付，报文完整性检查 (可选)

2. 检查和 checksum，对传输的报文进行检错
   - 发送端：将报文看成是由 16 比特整数组成的序列，对这些序列计算检查和
   - 接收端：对报文进行相同计算，与报文中的 checksum 进行比较，若相等则认为没有错误

3. UDP 的必要性
    - 应用会尽可能快地发送报文，没有建立连接的延迟，不限制发送速率，不进行拥塞控制和流量控制，
    - 包头开销小
    - 协议处理简单

4. 适合 UDP 的应用：容忍丢包但对延迟敏感的应用，如流媒体；以单词请求/响应为主的应用，如 DNS

5. 若应用要求基于 UDP 且进行可靠传输，就需要由应用层实现可靠性

## 可靠数据传输原理

1. 可靠传输是因特网的重要设计问题
   - 对于有些应用，一比特的错误都可能导致传输的数据无效
   - 在因特网这样的大规模网络中，数据传输极易出错
   - 可靠传输在链路层、传输层、应用层都需要实现

2. 可靠传输的服务抽象：数据通过一条 **理想信道**传输，数据不会有比特损坏或丢失，并按照发送的顺序被接收
   - 但实际使用的都是不可靠信道，而不可靠信道的特性决定了可靠数据传输协议的复杂性

3. 考虑单向数据传输，控制信息可以双向传输，从理想信道模型开始，增量开发，考虑如下信道
   - 理想信道，下层信道完全可靠，没有比特错误，也不会丢包，假设发送能力不大于接受能力 (不会出现来不及接收的现象)
     - 发送端和接收端的有限状态机均只有一个状态，发送端从上层接收数据，封装成分组送入下层信道，接收端从下层信道接收分组，取出数据交给上层
   - 可能有比特错误，但不会丢包，可以通过某种检错码检测比特错误
     - 从错误中恢复：肯定确认 ACK 显式告诉发送端收到分组正确，否定确认 NAK 显式告诉发送端收到分组错误，发送端收到 NAK 后重传
     - 发送端的有限状态机增加一个等待反馈的状态
     - 如果 ACK 或 NAK 出错，则发送端会重传分组，但就会在接收端产生 **冗余分组**，需要给分组添加一个 **序号**，接收端根据序号检测冗余分组并丢弃
     - 如果单个分组发送成功再发送下一个分组，只需一个比特的序号
     - 只使用 ACK 而不使用 NAK，对于出错的分组，重发最近一次的 ACK
   - 可能有比特错误，也可能丢包
     - 需要机制来检测丢包，以及从丢包中恢复
     - 检测丢包，若发送端在 “合理的” 时间内未收到 ACK 认为丢包，需要定时器
     - 从丢包中恢复，发送端重发当前分组

4. 可靠传输协议的设计过程
   - 出错类型：比特错误，丢包
   - 发现错误：检错码，定时器
   - 恢复措施：重发
   - 恢复措施引入问题：冗余分组
   - 解决冗余分组问题：序号
   - 汇总以上措施，画出各种情况下的时间线图
   - 归纳出有限状态机

5. rdt3.0 是一种停-等 (stop-and-wait) 协议
   - $U_{sender}=\frac{L/R}{RTT+L/R}$
   - 正确，但性能不佳

6. 流水线：提高链路利用率，允许发送端有多个已发送、未确认的分组
   - 分组的序号范围应扩大
   - 发送端和接收端可能需要缓存多个分组
   - 两种基本流水线协议：Go-Back-N 和 Selective Repeat

7. Go-Back-N 的收发规则
   - 发送端最多允许 N 个已发送未确认的分组；对最早的已发送未确认的分组使用一个定时器；定时器超时，从最早已发送未确认的分组开始，顺序发送其后分组
   - 接收端每收到一个分组，都要发送一个带序号的 ACK；对于未按顺序到来的分组，丢弃，重发最近一次的 ACK；使用累积确认，若 ACK 包含序号 q，表明序号至 q 的分组均已正确接收

8. Go-Back-N 的概念和术语
   - 发送端看到的 **序号空间(由序号长度决定)** 划分为以下区域
     - 已发送，已确认
     - 已发送，未确认
     - 未发送，可用
     - 不可用
   - 其中 **发送窗口** (N个序号)=已发送未确认+未发送可用
   - 基序号：发送窗口中第一个分组的序号
   - 下一个序号：下一个将发送的分组的序号
   - 若发送端收到 ACK q，则更新基序号为 q+1，整体滑动发送窗口

9. 选择重传 Selective Repeat
   - 发送端仅重传认为未出错的分组，避免不必要的重传
   - 接收端需要缓存失序的分组，需对每个正确收到的分组单独确认 (不进行累积确认)
   - 发送的每个分组需要有一个单独的定时器，超时重传
   - 发送窗口，包含已发送未确认、未发送可用，可能有已发送已确认；基序号是已发送未确认或未发送可用的序号；收到基序号的 ACK 时，滑动发送窗口
   - 接收窗口，包含期待但未收到、允许接收，可能有已确认已缓存；基序号为期待但未收到或允许接收；收到基序号分组时按顺序交付分组，滑动接收窗口
   - 通常发送窗口大小和接收窗口大小相同，而要使接收端不把重发的分组当作新分组，则两个满窗口不能重叠，因此窗口大小不能大于序号空间的一半

10. 流水线机制的设计
    - 一次允许发送多个分组的新问题：序号长度和窗口大小的关系，分组出错怎么处理
    - GBN：发现出错后，接收端不再接收新的包，双方从出错的包开始重传
    - SR：发现出错后，接收端继续接收接收窗口内的包，之后仅发送出错的包
    - 画出时间线图，归纳出有限状态机

11. 下层信道模型的一个遗留假设：可能发生比特错误、丢包和 **分组重排序** 的下层信道
    - 后发的分组可能早于先发的分组到达
    - 当连接两端的信道时一个网络时，可能发生重排序
    - 新问题：一个很老的分组可能到达接收端，且序号刚好落在当前接收窗口内
    - 假设分组在网络中的存活时间不超过某个固定值，使用很长的序号，确保序号回绕时间超过该固定值

## 面向连接的传输 - TCP

1. TCP 服务模型：连接一对通信进程的、理想的字节流管道
   - 点到点的通信
   - 全双工：可以同时双向传输数据
   - 可靠有序的字节流，不保留报文边界
   - 建立连接：通信双方为本次通信建立数据传输所需的状态 (套接字、缓存、变量等)
   - 流水式发送报文段
   - 流量控制：调整发送速率，不使接收端缓存溢出

2. TCP 选项
   - 最大段长度 MSS：段中可以携带的最大数据字节数，缺省为536字节
   - 窗口比例因子 window scale：实际接收窗口大小=窗口大小*2^窗口比例因子
   - 选择确认 SACK：允许接收端指出缺失的数据字节

3. 序号和确认序号
   - 序号：报文段中第一个数据字节的序号
   - 确认序号：累积确认，指出期望从对方接收的下一个字节的序号

4. TCP 超时设置
   - 如果超时值太小，则会产生不必要的重传；如果超时值太大，则丢失恢复时间太长；且应该大于 RTT，不过 RTT 是变化的
   - 估计 RTT
     - 采样 SampleRTT，测量从发出的某个报文段到收到其确认报文段之间经过的时间，不过这也是波动的
     - 平均 EstimatedRTT=(1-a)*EstimatedRTT+a*SampleRTT
       - 指数加权移动平均
       - a=0.125
     - 瞬时 RTT 和 平均 RTT 有很大的误差，应当在 EstimatedRTT 上加一个 “安全” 值，这也和 RTT 的波动有关
       - DevRTT=(1-b)*DevRTT+b*|SampleRTT-EstimatedRTT|
       - b=0.25
       - TimeoutInterval=EstimatedRTT+4*DevRTT

5. 高度简化后的 TCP 协议，仅考虑可靠传输，且数据单向传输
   - 接收端仅在正确、按序收到报文段后更新确认序号，否则重复前一次的确认序号；缓存失序的报文段
   - 发送端流水式发送报文段；仅对最早未确认的报文段使用一个定时器；仅在超时后重发最早未确认的报文段

6. TCP 减少重传的机制
   - 仅使用一个定时器，避免超时设置过小，重发大量报文段
   - 利用流水式发送和累积确认，避免重发某些丢失了 ACK 的报文段

7. TCP 确认的二义性
   - TCP 报文段的重传给 RTT 估计带来问题
   - TCP 是对接收到的数据而不是对携带数据的报文段进行确认，因此 TCP 的确认是有二义性的
   - 对重传报文段的 RTT 的估计不准确
   - 忽略有二义性的确认，只对一次发送成功的报文段测量 SampleRTT，并据此更新 EstimatedRTT 和 DevRTT
   - 当 TCP 重传一个段时，停止测量 SampleRTT，直到收到对该段的确认
   - 但需要引入定时器补偿，因为重传意味着超时设置偏小
   - 补偿，每重传一次，将超时设置加倍，直到一个设定的上限

8. Karn 算法，结合使用 RTT 估计值和定时器步长策略

9. TCP 接收端，理论上只需区分两种情况：收到期待序号的报文段，发送更新的确认序号；否则重复当前确认序号
   - 减少通信量，允许接收端 **推迟确认**，可在收到若干报文段后发送一个累积确认的报文段
   - 但推迟确认存在缺点：延迟太大，引起不必要重传；引起 RTT 估计不准确
   - 规定推迟确认最多延迟 500ms，且至少每隔一个报文段使用正常方式进行确认

10. **快速重传**：仅靠超时重传，恢复太慢
    - 利用重复 ACK 检测报文段丢失：发送端通常连续发送多个报文段，若报文段丢失，会有很多重复 ACK 发生，多数情况下 IP 按序交付分组，重复 ACK 极有可能因丢包产生
    - 规定发送端收到对同一序号的报文段的三个重复 ACK，就重传对应的报文段，而不等待超时

11. TCP 结合了 GBN 和 SR 的优点，在减小定时器开销和重传开销方面要优于 GBN 和 SR

12. 流量控制
    - 进入接收缓冲区的数据不一定被立即取走，取完
    - 若应用消费数据的速度较慢，接收缓冲区可能溢出，造成数据丢失- 而在接收缓冲区中的数据不会被 TCP 协议检测到，不会重发
    - GBN 和 SR 均假设正确、按需到达的分组被立即交付给上层，占用的缓冲区被立即释放，因此不会出现接收端缓冲区溢出的问题
    - UDP 不保证交付，数据丢失不违反 UDP 的服务承诺

13. 流量控制的机制
    - 接收缓冲区中的可用空间为 **接收窗口**，RcvWindow = RcvBuffer - [LastByteRcvd - LastByteRead]
    - 接收端将 RcvWindow 告知发送端，发送端根据 RcvWindow 调整发送速率，LstByteSent - LastByteAcked <= RcvWindow
    - 当发送端收到 RcvWindow=0 的报文段 (**零窗口通告**)时，停止发送，启动一个定时器，超时后发送一个 **零窗口探测** 报文段，接收端在响应的报文段中通告当前的接收窗口，零窗口探测的唯一作用就是 **触发接收端发送响应**
    - 糊涂窗口综合征：当发送很快、消费很慢时，这种简单实现会导致接收端不断发送微小窗口通告，发送端不断发送很小的数据分组，导致大量带宽被浪费
      - 接收端启发式策略：通告零窗口之后，仅当窗口大小 **显著增加** 之后再发送更新的窗口通告，取缓存空间一半大小或一个 MSS 大小两者的较小值为显著增加；当窗口不满足时，推迟发送确认，同之前的，最多推迟 500ms，且至少每隔一个报文段使用正常方式进行确认，且仅当大小满足时，才通告新的窗口大小
      - 发送端启发式策略：发送端应积聚足够多的数据再发送，避免发送太短的报文段；引入 Nagle 算法

14. Nagle 算法：适应网络延时，MSS 长度及应用速度的各种组合，且常规情况下不影响网络的吞吐量
    - 在新建连接上，应用数据到来时，组成一个 TCP 段发送
    - 在收到确认之前，后续到来的数据放在发送缓存中
    - 当数据量达到一个 MSS 大小或上一次传输确认到来，则将发送缓存中的数据传走

15. 连接管理
    - 建立连接要确认：双方都同意建立连接 (知晓对方要建立连接)，初始化连接参数 (序号、MSS 等)
    - 两次握手不行，因为可能出现已失效的连接请求报文段，服务器收到后误认为是客户端发出的请求，于是向客户端发出确认，但客户端不会理会，因为已经建立了连接，服务器会一直等待

16. 三次握手
    - 客户端发送 SYN=1，ACK=0，Seq=x，Ack无效 到服务器，进入 SYN-SENT 状态，不包含数据
    - 服务器收到后，发送 SYN=ACK=1，Seq=y，Ack=x+1 到客户端，进入 SYN-RCVD 状态，不包含数据 (服务器初始化缓存和变量)
    - 客户端收到后，发送 SYN=0，ACK=1，Seq=x+1，Ack=y+1 到服务器，进入 ESTABLISHED 状态，同时可以发送数据 (客户端初始化缓存和变量)
    - 服务器收到后，进入 ESTABLISHED 状态

17. 握手中如何选取初始序号
    - 若都从1开始，则每次新建连接会互相干扰
    - 若随机，干扰概率变小，但依然有可能
    - 但**必须避免新旧连接上的序号重叠**
    - 基于时钟的初始序号选取算法，每个主机使用一个时钟，以二进制计数器的形式工作，每经过 $\Delta T$ 时间，计数器加一，新建一个连接时，以计数器值最低 32 位作为起始序号，确保 **连接的初始序号随时间单调增长**
      - 取 $\Delta T$ 较小，确保起始序号的增长速度超过 TCP 连接上序号的增长速度
      - 使用较长的序号，确保序号回绕的时间远超过分组在网络中的最长寿命

18. 关闭连接
    - 发送端发送 FIN=1，Seq=x 到接收端，进入 FIN-WAIT-1 状态，此后不能发送，但仍能接收
    - 接收端收到后，发送 ACK=1，Ack=x+1 到发送端，进入 CLOSE-WAIT 状态，此时仍能发送
    - 发送端收到后，进入 FIN-WAIT-2 状态，此时不能发送，但仍能接收，等待服务器关闭
    - 接收端在把所有数据发送完毕后，发送 FIN=1，Seq=w 到发送端，进入 LAST-ACK 状态，此后不能发送，但仍能接收
    - 发送端收到后，发送 ACK=1，Ack=w+1 到接收端，进入 TIME-WAIT 状态，此时不能发送，但仍能接收，等待 2MSL (max segment lifetime) 后，进入 CLOSED 状态
    - 接收端收到后，进入 CLOSED 状态

19. SYN 洪泛攻击：针对服务器在收到 SYN 段后发送 SYNACK 段，分配资源，若未收到 ACK 段，服务器超时后重发 SYNACK 段，等待一段时间 (SYN 超时)后丢弃未完成的连接，而 SYN 超时典型值为 30 秒到 120 秒，因此攻击者可以发送大量的 SYN 段，而不发送 ACK 段，占用服务器资源，导致服务器无法建立新的连接

20. 端口扫描
    - 扫描程序利用与目标机器建立 TCP 连接过程中获得的响应消息来收集信息
    - 发送 SYN 段，若收到 SYNACK 段，表明有服务在运行；若收到 RST 段，表明没有服务在运行；若什么也没有收到，则表明端口有防火墙，丢弃来自外网的 SYN 段

21. FIN 扫描
    - 向目标端口发送 FIN 段，若收到 ACK=1，RST=1 的 TCP 段，表明端口上没有服务在监听；若没有响应，则表明端口上有服务在监听
    - 但有些系统的实现不符合以上的协议规定

## 拥塞控制原理

1. 网络拥塞
   - 起因：大量分组短时间内进入网络，超出网络的处理能力
   - 表现：网络吞吐量下降，分组延迟增大
   - 措施：减少分组进入网络 (拥塞控制)

2. 流量控制是使发送速度不超过 **接收端** 的处理能力；拥塞控制是使发送速度不超过 **网络** 的处理能力

3. 拥塞发生在路由器中：对某条输出链路而言，当进入该链路的数据速率接近或超过链路带宽时，就会发生拥塞
   - 即使不考虑丢包，当链路接近满载时，排队延迟急剧增大
   - 考虑路由器输出缓存溢出，则需要重传被丢弃的包，带宽会因重传而被浪费
   - 发送端定时器过早超时，不必要的重传浪费带宽
   - 两个 TCP 连接共享一条链路，一个连接或占用另一个连接的带宽，且若其中一个连接的分组被丢弃，上游用于传输该分组的带宽和缓存空间都被浪费

4. 拥塞控制方法
   - 端到端的拥塞控制：网络不向端系统提供显式反馈；端系统通过观察丢包和延迟来 **推断** 拥塞的发生，进而降低发送速率，是 TCP 采用的方法
   - 网络辅助的拥塞控制：发生拥塞的路由器向相关的发送端/接收端提供直接反馈，分为前向反馈 (通过接收者的网络反馈)和后向反馈 (直接网络反馈)，指示拥塞程度或直接给出发送速率，发送端相应降低发送速率，是 TCP ECN，ATM，DECbit 采用的方法

## TCP 的拥塞控制

1. TCP 使用端到端拥塞控制机制
   - 发送端根据自己感知的网络拥塞程度限制发送速率

2. 如何感知
   - 利用丢包事件感知拥塞
   - 丢包或分组延迟过大对于发送端来说都是丢包
   - 丢包事件包括超时和三次重复 ACK

3. 发送方使用拥塞窗口 CongWin 限制已发送未确认的数据量：LastByteSent - LastByteAcked <= CongWin
   - 则发送速率约为 SenderRate = CongWin / RTT
   - 拥塞窗口大小应随所感知的网络拥塞程度而变化

4. 加性增、乘性减 AIMD
   - 乘性减：发送方每检测到一个丢包时间，则将拥塞窗口减半，但不能小于一个 MSS
   - 加性增：若没有丢包，则每经过一个 RTT，拥塞窗口加一 MSS，直到检测到丢包

5. TCP 慢启动
   - AIMD 加得太慢，希望迅速增大 CongWin 到可用
   - 思想：在 **新建连接** 上指数增大 CongWin，直到出现丢包事件
   - 策略：经过一个 RTT，CongWin 加倍，直到出现丢包事件
   - 具体实施：每收到一个 ACK，CongWin 增大一个 MSS
   - 特点：以一个很低的速率开始，按指数增大发送速率

6. 区分不同的丢包事件
   - 收到三个重复 ACK，表明网络仍有一定交付能力，CongWin 减半，采用 AIMD 调节
   - 超时，说明网络交付能力很差，使用慢启动从 CongWin = 1MSS 开始增大 CongWin，直到超时发生时 CongWin 的一半后再采用 AIMD 调节

7. 实现
   - 发送方维护一个变量 Threshold
   - 发生丢包时，Threshold 变为当前 CongWin 的一半
     - 若收到三个重复 ACK，CongWin 变为 Threshold+3MSS，执行 AIMD
     - 若超时，CongWin 变为 1MSS，执行慢启动
   - 在 CongWin < Threshold 时，执行慢启动；在 CongWin > Threshold 时，执行 AIMD (拥塞避免)

8. TCP 吞吐量，估计一个长期存活的 TCP 连接的平均吞吐量
   - 发生丢包时的 CongWin 大小为 W，此时吞吐量为 W/RTT
   - 发生丢包后调整 CongWin 为 W/2，此时吞吐量为 W/2RTT
   - 假设 W 和 RTT 不变，则平均吞吐量为 0.75W/RTT

9. 一条 TCP 连接的平均吞吐量与丢包率 L 的关系为 $Throughput=1.22MSS/RTT\sqrt{L}$

10. TCP 的公平性：如果 K 条 TCP 连接共享某条带宽为 R 的瓶颈链路，每条连接具有平均速度 R/K，则称这些连接是公平的
    - 若每条连接的参数相同，则会趋向于公平
    - 但如果各条连接的参数不同，则不能保证公平性
    - 若应用建立多条并行 TCP 连接，不能保证带宽在应用间公平分配

11. 公平性和 UDP
    - 多媒体应用通常不适用 TCP，不希望拥塞控制限制发送速率
    - 宁愿使用 UDP，即使可能要承受少量丢包
    - 不过 UDP 缺少拥塞控制，感知不到拥塞，也不会降低发送速率，影响应用及网络的整体性能
    - UDP 对 TCP 协议不友好，损害网络公平性
    - 给 UDP 加上拥塞控制，DCCP = UDP + 拥塞控制
